---
layout: post
title: "[AI 개발] QA 엔지니어로 일하며 AI 도구로 테스트 케이스 관리툴 만든 경험담-1부 LLM 사용기"
date: 2025-08-10 20:42:00 +0900
categories: ai-development
tags:
- ai
- test-management
- claude
- perplexity
- cursor
- llm
---

* 목차
{:toc}

---

QA 엔지니어로 일하면서 자연스럽게 쌓이는 고민이 있죠. 바로 테스트 케이스 관리입니다.

최근에 여러 AI 도구들을 활용해서 테스트 케이스 관리툴을 직접 만들어보면서, 각 도구의 장단점과 한계를 몸소 경험할 수 있었어요. 어떤 여정을 거쳤는지, 그리고 각 도구에서 어떤 깨달음을 얻었는지 솔직하게 정리해보겠습니다.

깨달음까지는 아니고 그냥 사용기라고 보시면될것같아요..

- 1부에서는 LLM 사용기
- 2부에서는 테스트메이스 관리툴 설명
- 3부에서는 아직 3부까지는 모르겠습니다.

## 왜 왜? 테스트 케이스 관리툴을 만들게 됐을까요??

<table>
  <tr>
    <td><img src="/assets/images/d9b196cb-d401-4cb7-87a3-41748c357ba5.png" alt="테스트 케이스 관리툴" width="900" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"></td>
  </tr>
</table>>

오.. 오랜 시간 QA 엔지니어로 일하다 보면, 소프트웨어 품질 관리와 테스트 케이스 작성에 대한 고민이 자연스럽게 쌓입니다.

엑셀, 구글 시트, TestRail, Testmo, TestLink 같은 여러 툴을 두루 써봤는데, 쓸 때마다 "이건 편한데, 저건 불편하네"라는 생각이 들었어요.

## 엑셀과 구글 시트의 딜레마
엑셀이나 구글 시트는 테스트 절차 설명과 결과 기록, 함수로 자동화까지 꽤 유용하게 쓸 수 있습니다. 단순한 프로젝트에서는 많이들 선택하는 이유가 있죠.

하지만 기본적으로 '수동' 도구라서, 테스트가 많아질수록 누락이나 실수, 관리의 번거로움이 눈에 띄게 늘어납니다. 게다가 한 번 만든 문서가 의외로 쉽게 흩어져 버릴 위험도 커요. 담당자가 퇴사하거나 공유를 깜빡하면 문서 위치 찾느라 진땀을 빼야 할 때가 많죠.

공유를 깜빡하면 문서 위치 찾느라 진땀을 빼야 할 때도있었고, 링크가 끊키는 경우도 있고 했던것같아요.

### 오픈소스의 현실
그래서 오픈소스를 검색해보게 되죠 오픈소스를 검색하면 가장 먼저 눈에 띄는 TestLink. 

한때 오픈소스 대표주자로 이름을 알렸지만, 실제 현장에서는 그리 자주 쓰이지 않았던 것 같습니다. 공식 지원도 중단되고, 점점 설 자리가 좁아지는 느낌이에요.

## 상용툴의 아쉬움
물론 TestRail이나 Testmo, Zephyr, Xray 같은 상용툴들을 쓰면 손쉽게 사용할 수 있습니다. 기존 툴을 사용하다 보면, 있으면 좋겠지만 구현이 어려운 기능들이 있었고, 툴에 맞춰서 내 방식이 희생되는 경험이 많았거든요,

내 입맛에 맞는 툴을 직접 개발하면 더 꼭 맞게 사용할 수 있을 것 같다는 욕심이 컸어요. 


## 새로운 시대의 새로운 가능성: LLM과의 만남
툴에 맞춰지기보다는 내가 필요한 기능을 만들어서 쓰는 것이 더 낫다는 생각이 들었습니다. 게다가 요즘은 LLM 시대잖아요. LLM 모델들을 활용하면 개발이 훨씬 수월할 것이라고 생각해서 "한 번 만들어보자"는 마음이 피어올랐습니다.

제가 이번에 툴을 만들면서 사용했던 LLM들은 Perplexity, ChatGPT, Cursor, Gemini, Claude 여러가지를 써봤습니다.

ChatGPT의 경우, 전반적인 내용을 파악할 수 있는 상세한 답변을 주지만, 답변 중 서론이 길고 반복적인 내용을 포함한 경우가 많아 요지 파악이 어려운 때가 있었어요.

Cursor와 Claude의 조합은 정말 인상적이었습니다. Claude는 프롬프트 의도와 맥락 파악을 잘하며 주요 포인트를 정확히 짚어내더라고요.

Gemini는 초기에 프롬프트 의도를 제대로 파악하지 못하고, 오류들도 상당히 많은았던것같아요 아직 초기버전이라 그런가? 아니면 사용을 못해서 그런지 보조도구로 사용중이에요 

아무튼 조금씩 공부하고 실전에 임하다 보니, 예상보다 훨씬 더 흥미로운 경험이었습니다.

무엇보다 중요한 건, 이런 경험이 비슷한 고민을 하고 계신 다른 QA 엔지니어분들께 도움이 되길 바라는 마음입니다. 

혹시 궁금한 점이나 추가로 원하는 방향이 있으시면 언제든 말씀해 주세요.

---

# 개발 과정 타임라인

### 1단계: 초기 - 복사 붙여넣기 방식 (Perplexity/ChatGPT)
<table>
  <tr>
    <td><img src="/assets/images/perplexity-vs-chatgpt.webp" alt="테스트 케이스 관리툴" width="900" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"></td>
  </tr>
</table>>

처음에는 가장 기본적인 방식으로 시작했습니다.
Perplexity나 ChatGPT를 이용해서 코드를 생성하고, 
복사해서 붙여넣기 하는 방식으로 작업을 진행했어요.

코드를 직접 읽고 손보는 재미가 있었어요. AI가 만들어준 코드를 곰곰이 파악하면서 배우는 느낌이 진짜 좋았던것같아요 

이해 안 가는 부분이 있으면 계속 질문해서 파고드는 과정이 꽤 재밌었어. 마치 혼자서 튜터링 받는 느낌..

그런데, 반복되는 질문이나 코드 구문이 많아서 좀 지루해질 때도 있었어요 질문이 반복되다 보니, 이미 했던 대화를 또 되풀이하는 기분이 들더라고요.

코드에서 문제가 하나 고쳐지면, 또 다른 데서 오류가 생기고

그걸 고치면 다시 원점으로 돌아가는... 약간 뫼비우스의 띠같은 경험도 ㅋㅋ

그리고 파일 용량이나 크기 제한 때문에 작업이 자주 끊겨서 불편했어.

뭐든 복붙(복사 붙여넣기) 하는 게 은근히 귀찮더라 고요 , 어디를 수정해야 할지 파일이나 코드 위치 찾는 데 시간이 많이 들었어.

정리해보면.. 

**좋았던점:**
- 코드를 읽고 수정하는 재미가 있었음 
- AI가 생성한 코드를 이해하면서 학습할 수 있었음
- 내가 이해 못하는 부분을 반복적으로 물어보고 학습하는 기분이 들어서 좋았음.

**아쉬웠던점:**
- 반복적인 구문이 많았음
- 질문을 반복해서 하다보면 기존에 했던 내용들이 반복되는것같았음.
- 오류순환 1개를 고치면 다른곳을 수정해서 다시 원점으로 돌아가는경우가 있었음.
- 파일 크기 제약으로 인한 불편함
- 복사 붙여넣기의 번거로움
- 어느 위치를 수정해야 할지 찾아야 하는 시간이 많이 들었음.

이 시점에서 "커서나 RAG 같은 도구를 사용하면 더 효율적일 것 같다"는 생각이 들었습니다.


### 2단계: 파일 기반 검색 (Perplexity 파일 기능)
<table>
  <tr>
    <td><img src="/assets/images/perplexity_space.png" alt="테스트 케이스 관리툴" width="200" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"></td>
  </tr>
</table>>
- perplexity 공간- 
처음엔 그냥 복사-붙여넣기 방식으로만 작업했는데,

Perplexity 공간에 파일 업로드 기능이 있다는 걸 알고 나서는 상황이 조금 달라졌습니다.

저는 마침 SK에서 1년간 무료 구독을 제공해 줘서, 망설임 없이 계속 사용했죠.
(SK 해킹사고이전에 가입한거라 쭈~욱 써오고 있었죠)

무료 버전이면 파일 업로드가 5개밖에 안 되지만, 구독 버전은 최대 50개까지 가능하거든요.

기존에 복붙하던걸 질문만 하면되었습니다.
이게 생각보다 꽤 큰 차이였습니다.

그래서 한 번에 50개의 파일을 올려놓고 작업을 진행했어요.
Backend랑 Frontend 파일을 따로 공간(Workspace)로 나눠서 질문하면서요.
처음엔 프로젝트 전체가 102개 파일 정도였는데, 그 정도면 두 공간으로 나누면 다 커버가 됐습니다.

덕분에 AI가 제 프로젝트의 전체 파일 구조를 인식한 상태에서 코드를 제안해 줄 수 있었어요.
예를 들어, "이 함수에서 호출하는 다른 모듈이 어디 있었죠?" 같은 질문을 해도 당황하지 않고 척척 대답해주더라고요.

결국 이 단계에서는
프로젝트 전체의 뼈대를 잡고, 필요한 기본 기능들을 구현하는 데 큰 무리가 없었습니다.
파일 기반으로 컨텍스트를 제공하니, 구조화나 리팩토링에도 훨씬 유리했죠.

**좋았던점**
- RAG는 아니지만, 전체 파일 구조를 이해한 상태로 작업 가능
- 파일 구조 변경, 리팩토링 작업에 아주 용이
- 프로젝트 전체 맥락을 고려한 코드 생성 가능

**아쉬웠던 점**
- 여전히 수정은 복사-붙여넣기로 진행해야 함
- 파일 업로드 제한(50개) 때문에 아주 대규모 프로젝트는 나눠서 처리해야 함

정리하자면,
이 단계에서 저는 **'LLM이 구조를 이해한 상태에서 작업한다'**가 얼마나 강력한지 직접 체감했습니다.
다만, 결국 최종 수정은 사람 손으로 해야 했고, 파일 개수 제한이라는 벽이 있었죠.

그래서 다음 목표는 분명해졌습니다.
복붙 없이, 더 많은 파일을 한 번에 읽고 바로 적용할 수 있는 환경.
이걸 갖추면, 이제 진짜 LLM이랑 나란히 앉아서 코딩하는 걸 찾아보게되었죠 


### 3단계: 자동 코드 생성 (Cursor, Kiro)
<table>
  <tr>
    <td><img src="/assets/images/Cursor_Kiro.png" alt="테스트 케이스 관리툴" width="500" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"></td>
  </tr>
</table>

Perplexity의 파일 업로드 기능만 써도 충분하다 싶었는데, 어느 날 Cursor라는 에디터를 알게 됐어요.

여기서부터는 진짜 다른 차원의 경험이 시작됐습니다.

복사 붙여넣기가 아니라, 그냥 파일을 열고 “이 부분 고쳐줘” 하고 말만 하면 LLM이 알아서 코드를 직접 수정해주더라고요.

심지어 실행, 빌드까지 바로 할 수 있고 테스트 코드도 척척 만들어주니…

요즘 말로 “바이브 코딩”의 세계가 여기 있었구나 싶었어요.

그전엔 “AI가 옆에서 도와준다” 느낌이었다면, Cursor에서는 “AI랑 같이 코딩한다” 느낌이 훨씬 강해집니다.

요청만 하면 알아서 코드 생성, 수정, 테스트, 문제 확인까지 자동으로 돌아갑니다.

아무리 복잡한 기능도 “이렇게 만들어줘” 하면 정말 알아서 다 해줘요.

물론 처음엔 무료 버전으로 써봤는데요,

속도가 살짝 느리고 코드 신뢰도가 기대보다는 좀 떨어졌어요.

그래서 바로 유료 결제를 했죠. 요즘은 계속해서 구독 결제를 반복하게 만드는것같습니다. 

유료 버전으로 바꾸고 나서부터는 속도, 품질 둘 다 크게 나아졌습니다.

정말 “AI 개발자랑 나란히 앉아서 일하는 것 같다”는 느낌이 듭니다.

하지만 행복도 잠시,

1주일 지나니까 “사용량 초과” 안내가 뜨더라고요.

고급 모델은 못 쓰고, 간단한 기능만 제한적으로 사용할 수밖에 없었습니다.

완전히 막힌 건 아니지만, 바이브 코딩의 짜릿함이 살짝 줄어드는 순간이었죠.

쉽게 말하면요,

저는 Cursor 덕분에 진짜 “신세계”를 경험했습니다.

하지만 제약이 전혀 없는 건 아니란 걸, 또 한 번 알게 됐죠.

**신세계를 경험한 부분:**
- 요청만 하면 AI가 알아서 다 해줌
- 코드 생성, 수정, 테스트 코드 작성까지 자동화
- 문제가 있는지 없는지 확인까지 해줌

처음에는 무료 버전을 사용했는데, 속도가 느리고 코드 신뢰도가 떨어져서 유료 결제를 하게 되었습니다.

**유료 버전 사용 후:**
- 속도와 품질이 크게 향상
- 하지만 1주일 정도 사용하고 나니 사용량 초과로 고급 모델 사용 불가
- 완전히 사용 못하는 건 아니지만, 제한적인 기능만 사용 가능

Cursor로 ‘바이브 코딩’의 신세계에 푹 빠져 있었던 터라, 새로운 AI 도구 소식에 꽤 기대했어요.

그중에 무료로 풀렸다는 KIRO 소식을 듣고는 바로 접해봤죠.

KIRO는 Cursor와는 조금 다른 매력이 있었습니다.

제가 직접 테스트하던 부분까지 자동으로 생성해주고, 테스트를 돌리고, 실행 계획을 짜고, 심지어 요구사항 문서도 만들어주는…

마치 AI가 개발뿐만 아니라 기획과 검증까지 다 알아서 해주는 느낌이었어요.

처음엔 ‘와, 이거 진짜 대단한데?’ 하면서 신선한 충격을 받았습니다.

기존에 제가 겪었던 불편함들이 꽤 해소되는 듯했거든요.

어쩌면 이게 앞으로 AI 코딩의 새로운 방향이라는 생각도 들었어요.

하지만 역시 현실의 벽은 거기서도 마주하더군요.

초반에는 정말 잘 돌아가다가, 어느 순간 사용량 초과 메시지가 떠서 “잠시 후에 다시 시도해 주세요”라는 안내만 나오기 시작했어요.

무료 서비스라 그런지 한계가 명확했죠.

그래서 자연스레 KIRO는 잠시 뒤로 물러나게 됐습니다.

기대를 많이 했던 만큼 아쉬운 마음도 컸죠.

쉽게 말하면요,

KIRO는 저에게 또 한 번의 ‘신세계’를 보여줬습니다.

LLM 코딩 (바이브코딩)을 넘어서 테스트와 요구사항 작성까지 함께 하는 미래가 이렇게 가까이 있구나 하고 느꼈거든요.

하지만 무료 모델의 사용량 제한은 결국 현실이라는 걸 다시 한 번 깨달았죠.

근데 여기서 느낀건 다들 Claude 의 Sonet 4 모델을 쓰더군요 

때마침 Claude code 프로모션 코드가 있어서 그걸 써보기로 하였습니다.  

### 4단계: Claude Code로 전환

어디였는지는 기억이 나지 않습니다. 

프로모션 코드 를 입력하면 $20 를 $10에 3개월 이용할수 있게 하는 프로모션을 이용해서 Claude code를 사용해보기로 하였습니다.

Cursor, Kiro 도 모두 Sonet 4 를 이용하니 클로드에서 제공하는게 낳겠다 싶기도 했고요.. 

실행하는 과정은 Cursor 와 크게 다르지 않았습니다. 

다만 Cursor 는 IDE 기반이지만 Claude Code 는 터미널 기반이여서 처음 접하는 사람들은 어려울수도 있겠구나 하는 생각은 들었습니다.

하지만 전 터미널하고 좀 친하게 지내서 그렇게 어렵게 느껴지지는 안았습니다.

커서랑 다르게 좋은점은 제가 메이으로 사용하고 있는 IDE 가 InteliJ 인데 터미널기반이라 플러그인을 설치하면 커서와 같이 IDE에서 변경사항들을 보여주고 편집하는 것들을 볼수 있어서 

좋았던거 같아요..

Claude code 는 Super Claude 를 깔아서 같이 사용하면 좋다고 하여 한번 사용해봤어요...

그런데 문제가있더군요 '/sc:analyze' 를 하니 분석을 정말 잘해줬던거 같아요  

하지만 Claude 가 tocken 기반으로 과금이 되는 구조이다 보니 토큰양이 어머하게 소모되더군요.

아래는 토큰사용량입니다.

```

Token Usage : 53.8%    10,223 / 19,000

```
전체 중 50% 를 먹더군요.

<table>
  <tr>
    <td><img src="/assets/images/Claude_usage.png" alt="테스트 케이스 관리툴" width="500" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"></td>
  </tr>
</table>

가장 보기 싫은 화면입니다. 클로드 사용량에 도달해서 5시간을기다려야 하는

뭐 이정도 되니 내가 작업을 하는것이 아닌 외주 주고 시키는 것같은 생각이 들더라고요...

작업을 진행하다가 보면 저 화면을 자주보는데 어디까지 했는지 관리 하는 부분이 어려움이 있었어요..

그래서 내가 원래 하던방법 JIRA 에 기록하는 방법을 찾아보니 있더군요.

**결제 과정:**
- 10달러 프로모션으로 결제 진행
- 실제로는 11달러 결제됨 (부가세 포함)

**사용 경험:**
- 한도는 있지만 할 만한 수준
- 작업이 많아지면서 하루에 5시간씩 기다려야 하는 상황 발생
- 어느 작업까지 완료되었는지 추적이 어려워짐
- 내가 작업하는게 아닌 외주 주는것같은느낌.

MCP를 이용해서 JIRA 를 붙이고 JIRA 에 작업관리하고 상태관리를 하면 되겠다 싶었습니다.

그래서 MCP를 붙이게 되었죠.

### 5단계: 프로젝트 관리 도구 통합 (JIRA MCP, Playwright MCP)

사용량 제한 시간동안 까먹는 문제를 해결하기 위해 프로젝트 관리 도구인 JIRA 를 이용한건 잘한것같아요 

JIRA 를 기지고 작업 관리를 하게 되니 커맨드창에서 작업들이 어디까지 진행되었는지 이후에도 작업을 이어서 나갈수 있겠더라고요.

뭐 Claude 에서 Taskmaster를 이용하면 된다고는 하지만 그것보다는 기존에 사용하던 편한 방법으로 해보게 된거죠.

<table>
  <tr>
    <td><img src="/assets/images/mcp_jira.png" alt="테스트 케이스 관리툴" width="500" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"></td>
  </tr>
</table>
이미지와 같이 Claude 에서 에픽과 작업을 만들어서 이슈들을 연결해달라고 요청하면 작업을 연결하고 

작업이 완료되면 코맨트를 달고 하는 과정들이 이루어지게 되니좀더 관리가 되는 느낌을 받았어요.

작업들을 나눠서 할수도 있었고 시간이 지나서도 어떤것들을 했는지 확인할수 있게되어서 좋더라고요.

테스트도 붙이면 되겠구나 생각해서 찾아보니 역시나 그런것들이 있더군요...

ChatGPT ,Perplexity 를 쓸때 수동으로 Cypress 를 붙여서 테스트를 작성해서 E2E테스트를 수동으로 작성하고 했는데 

이것도 이제는 귀찬음의 영역이 되더군요..

그래서 Playwright MCP를 붙였습니다.

이걸 붙여놓으니 또 좀더 낳아지더군요 화면에 있는 내용들도 Clade 가 테스트를 수행하고 결과를 보여주고 그 결과를 보고 수정하고

저는 그냥 엔터만 쳐주고 확인하는 정도만 하는 수순으로..


아무튼 여기까지가 LLM 을 이용해서 테스트 케이스 관리툴을 만들기까지의 사용기 였습니다.

처음에는 내가 복붙 머신임을 느끼다가 엔터 머신으로 바뀌고 단지 보기만 하는 관찰자가 되는 과정....

누군가는 그러더군요 6개월 이상 지난 코드는 내가짠코드도 내코드가 아니다...

그런데 지금의 LLM 은 내가짠 코드도 아니고 단지 관찰만 하고 하니 이건 그냥 모두가 래거시 코드가 되는건 아닐찌...

그런 래거시 코드들이 안되기 위해 계속 사용하고 관찰하고 수정해봐야 겠다는 생각은 좀 들더라고요..

다음에는 테스트 케이스 관리툴의 전체적인 화면 설명과 왜 그 화면들이 있는지에 대해서 기술해볼게요..

<table>
  <tr>
    <td><img src="/assets/images/ict_testcase_01.png" alt="테스트 케이스 관리툴" width="400" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"></td>
  </tr>
  <tr>
    <td><img src="/assets/images/ict_testcase_02.png" alt="테스트 케이스 관리툴" width="400" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"></td>
  </tr>
</table>

이 화면이 만든 테스트 케이스 관리툴의 대시보드 화면입니다. 

익숙한 UI 이죠? LLM 이 만들어주면 비슷한 화면으로 나오더라고요.. 

그럼 다음을 기약하며 오늘은 여기까지입니다.
끝! 